# Project Description  
A new, redesigned screen reader for people with vision disabilities that utilizes AI/ML to help navigate web pages with ease and efficiency.

The system is described visually in our design diagrams.  Here, we provide an in-depth description of the system.  A visually impaired user surfing the web will be able to use our browser extension to get an audio description of the webpage that they are currently accessing.  In order to do this, the web extension will grab the webpage's Document-Object-Model (ruther referred to as DOM).  The DOM is sent to a service that will transform it into a data format that can be fed into a machine learning service.  We will have a service running a REST API that will handle moving this data between the user and the machine learning service.  The machine learning service will take the transformed DOM data and produce a tet description.  This text description will include important information about the pages content and exclude extraneous information that is not useful to the user.  The REST API service will send this text description to the web extension.  The web extension will use the text-to-speech API available in the user's browser to convert the text description to audio and play that audio to the user.
